

# ------------- ë°ì´í„° ë¶„ì„-----------------------------

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
from functools import reduce

# íŒŒì¼ ê²½ë¡œ
byc_path = "data/byc.csv"
pollution_path = "data/ì´ì‚°í™”ì§ˆì†Œ.csv"
ev_path = "data/ì§€ì—­ë³„ ì „ê¸°ì°¨.csv"
station_path = "data/ë²„ìŠ¤ ì¶©ì „ì†Œ.csv"

# ğŸš² ìì „ê±° ë°ì´í„°
byc_df = pd.read_csv(byc_path)

# 'ì‹œë„ë³„(1)' ì»¬ëŸ¼ëª…ì„ 'ì‹œë„'ë¡œ ë³€ê²½
byc_df.rename(columns={'ì‹œë„ë³„(1)': 'ì‹œë„'}, inplace=True)

byc_grouped = byc_df.groupby("ì‹œë„")[["ìŠ¤í…Œì´ì…˜ ê°œì†Œ (ê°œ)", "ìì „ê±°ë³´ìœ  (ëŒ€)"]].sum().reset_index()
byc_grouped.columns = ["ì‹œë„", "ìì „ê±°ìŠ¤í…Œì´ì…˜ìˆ˜", "ìì „ê±°ë³´ìœ ìˆ˜"]

# ğŸ”‹ ì „ê¸°ì°¨ ìˆ˜ ë°ì´í„°
elec_df = pd.read_csv(ev_path)

# wide -> long ë³€í™˜
elec_long = elec_df.melt(id_vars="ê¸°ì¤€ì¼", var_name="ì‹œë„", value_name="ì „ê¸°ì°¨ìˆ˜")
# ì§€ì—­ëª…ì´ 'ì„œìš¸' -> 'ì„œìš¸íŠ¹ë³„ì‹œ' ë“±ì˜ ì‹œë„ ì´ë¦„ê³¼ ë§ë„ë¡ ë³€í™˜ í•„ìš”
region_map = {
    "ì„œìš¸": "ì„œìš¸íŠ¹ë³„ì‹œ", "ë¶€ì‚°": "ë¶€ì‚°ê´‘ì—­ì‹œ", "ëŒ€êµ¬": "ëŒ€êµ¬ê´‘ì—­ì‹œ", "ì¸ì²œ": "ì¸ì²œê´‘ì—­ì‹œ",
    "ê´‘ì£¼": "ê´‘ì£¼ê´‘ì—­ì‹œ", "ëŒ€ì „": "ëŒ€ì „ê´‘ì—­ì‹œ", "ìš¸ì‚°": "ìš¸ì‚°ê´‘ì—­ì‹œ", "ì„¸ì¢…": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
    "ê²½ê¸°": "ê²½ê¸°ë„", "ê°•ì›": "ê°•ì›ë„", "ì¶©ë¶": "ì¶©ì²­ë¶ë„", "ì¶©ë‚¨": "ì¶©ì²­ë‚¨ë„",
    "ì „ë¶": "ì „ë¼ë¶ë„", "ì „ë‚¨": "ì „ë¼ë‚¨ë„", "ê²½ë¶": "ê²½ìƒë¶ë„", "ê²½ë‚¨": "ê²½ìƒë‚¨ë„",
    "ì œì£¼": "ì œì£¼íŠ¹ë³„ìì¹˜ë„"
}

def normalize_region(region):
    return region_map.get(region, region)  # ë§¤í•‘ ì—†ìœ¼ë©´ ì›ë˜ ì´ë¦„ ë¦¬í„´

# elec_dfëŠ” wide í˜•íƒœë¡œ (ì»¬ëŸ¼ ê³ ë ¤)
elec_long = elec_df.melt(id_vars=['ê¸°ì¤€ì¼'], var_name='ì‹œë„', value_name='ê°’')

# í•¨ìˆ˜ ì ìš©
elec_long["ì‹œë„"] = elec_long["ì‹œë„"].apply(normalize_region)

elec_grouped = elec_long.groupby("ì‹œë„")["ê°’"].sum().reset_index()
elec_grouped.columns = ["ì‹œë„", "ì „ê¸°ì°¨ìˆ˜"]

# print(elec_df.columns.tolist())
# print(elec_long.columns.tolist())
# print(elec_long['ì‹œë„'].unique())



# ì¶©ì „ì†Œ ìˆ˜ ë°ì´í„°
charge_df = pd.read_csv(station_path)
charge_df = charge_df.rename(columns={"êµ¬ë¶„": "ì‹œë„", charge_df.columns[1]: "ì¶©ì „ì†Œìˆ˜"})

# ë‘ ë²ˆì§¸, ì„¸ ë²ˆì§¸, ë„¤ ë²ˆì§¸ ì»¬ëŸ¼ì„ ë”í•´ì„œ 'ì¶©ì „ì†Œìˆ˜' ê³„ì‚°
cols_to_sum = charge_df.columns[1:4]  # ë‘ ë²ˆì§¸~ë„¤ ë²ˆì§¸ ì»¬ëŸ¼
charge_df["ì¶©ì „ì†Œìˆ˜"] = charge_df[cols_to_sum].sum(axis=1)

# ì‹œë„ë³„ë¡œ ì¶©ì „ì†Œìˆ˜ ì§‘ê³„ (í˜¹ì‹œ ë™ì¼ ì‹œë„ ì¤‘ë³µ í–‰ ìˆì„ ê²½ìš° ëŒ€ë¹„)
charge_grouped = charge_df.groupby("ì‹œë„")["ì¶©ì „ì†Œìˆ˜"].sum().reset_index()


charge_df = charge_df.groupby("ì‹œë„")["ì¶©ì „ì†Œìˆ˜"].sum().reset_index()

# í™•ì¸
# print(charge_df)

# ì´ì‚°í™”ì§ˆì†Œ ë°ì´í„°

# 1. ë¯¸ì„¸ë¨¼ì§€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
pollution_df = pd.read_csv(pollution_path)

# 2. ì—´ ì´ë¦„ ì •ë¦¬ (ê³µë°± ì œê±°)
pollution_df.columns = pollution_df.columns.str.strip()

# 3. í•„ìš”í•œ ì»¬ëŸ¼ ëª©ë¡ (2024.05 ~ 2024.10)
target_cols = ["2024.05", "2024.06", "2024.07", "2024.08", "2024.09", "2024.10"]

# 4. ë¬¸ìì—´ ìˆ«ìë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜ (ì‰¼í‘œ ì œê±° í›„ numeric)
for col in target_cols:
    pollution_df[col] = pollution_df[col].astype(str).str.replace(",", "").str.replace(" ", "")
    pollution_df[col] = pd.to_numeric(pollution_df[col], errors="coerce")

# 5. í‰ê·  ê³„ì‚° â†’ 'ë¯¸ì„¸ë¨¼ì§€ì–‘' ì»¬ëŸ¼ ìƒì„±
pollution_df["ì´ì‚°í™”ì§ˆì†Œì†Œ"] = pollution_df[target_cols].mean(axis=1)

# 6. ì‹œë„ ê¸°ì¤€ìœ¼ë¡œ í‰ê·  ì§‘ê³„ (êµ¬ë¶„(2)ë¥¼ ì‹œë„ë¡œ)
pollution_avg = pollution_df.groupby("êµ¬ë¶„(2)")["ì´ì‚°í™”ì§ˆì†Œì†Œ"].mean().reset_index()
pollution_avg.columns = ["ì‹œë„", "ì´ì‚°í™”ì§ˆì†Œ_í‰ê· "]

# 7. ì‹œë„ ì´ë¦„ í†µì¼ (ë³‘í•©ì„ ìœ„í•´)
region_map = {
    "ì„œìš¸íŠ¹ë³„ì‹œ": "ì„œìš¸", "ë¶€ì‚°ê´‘ì—­ì‹œ": "ë¶€ì‚°", "ëŒ€êµ¬ê´‘ì—­ì‹œ": "ëŒ€êµ¬", "ì¸ì²œê´‘ì—­ì‹œ": "ì¸ì²œ",
    "ê´‘ì£¼ê´‘ì—­ì‹œ": "ê´‘ì£¼", "ëŒ€ì „ê´‘ì—­ì‹œ": "ëŒ€ì „", "ìš¸ì‚°ê´‘ì—­ì‹œ": "ìš¸ì‚°", "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": "ì„¸ì¢…",
    "ê²½ê¸°ë„": "ê²½ê¸°", "ê°•ì›ë„": "ê°•ì›", "ê°•ì›íŠ¹ë³„ìì¹˜ë„": "ê°•ì›", "ì¶©ì²­ë¶ë„": "ì¶©ë¶", "ì¶©ì²­ë‚¨ë„": "ì¶©ë‚¨",
    "ì „ë¼ë¶ë„": "ì „ë¶", "ì „ë¶íŠ¹ë³„ìì¹˜ë„": "ì „ë¶", "ì „ë¼ë‚¨ë„": "ì „ë‚¨", "ê²½ìƒë¶ë„": "ê²½ë¶", "ê²½ìƒë‚¨ë„": "ê²½ë‚¨",
    "ì œì£¼íŠ¹ë³„ìì¹˜ë„": "ì œì£¼"
}

pollution_avg["ì‹œë„"] = pollution_avg["ì‹œë„"].apply(lambda x: region_map.get(x.strip(), x.strip()))

# 8. ê²°ê³¼ í™•ì¸
print(pollution_avg)


def normalize_region(region):
    region = region.strip()
    return region_map.get(region, region)

# ê° ë°ì´í„°í”„ë ˆì„ì— ì ìš©
byc_grouped["ì‹œë„"] = byc_grouped["ì‹œë„"].apply(normalize_region)
elec_grouped["ì‹œë„"] = elec_grouped["ì‹œë„"].apply(normalize_region)
charge_df["ì‹œë„"] = charge_df["ì‹œë„"].apply(normalize_region)
pollution_avg["ì‹œë„"] = pollution_avg["ì‹œë„"].apply(normalize_region)


# #------------------ì „ì²˜ë¦¬ ë ---------------------------------------------

# ë³‘í•© -> ì‹œë„ ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ
dfs = [byc_grouped, elec_grouped, charge_df, pollution_avg]
merged_df = reduce(lambda left, right: pd.merge(left, right, on="ì‹œë„", how="outer"), dfs)
# í†µí•© df

# ë³‘í•© ê²°ê³¼ í™•ì¸
# print("\n[ë³‘í•©ëœ ë°ì´í„°í”„ë ˆì„]")


# ê²°ì¸¡ê°’ ì œê±°
merged_df.dropna(inplace=True)

# ë§Œì•½ ì•ˆë˜ë©´ ê²½ê³  ì¶œë ¥
if merged_df.empty:
    raise ValueError("ë³‘í•© ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì‹œë„ëª…ì´ ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

print(merged_df)


# êµí†µ ì¸í”„ë¼ ì§€ìˆ˜ (ì •ê·œí™” í›„ í‰ê·  ëƒ„ëƒ„)
infra_cols = ["ìì „ê±°ë³´ìœ ìˆ˜", "ì¶©ì „ì†Œìˆ˜", "ì „ê¸°ì°¨ìˆ˜"]
scaler = MinMaxScaler()
merged_df[[f"{col}_ì •ê·œí™”" for col in infra_cols]] = scaler.fit_transform(merged_df[infra_cols])
merged_df["êµí†µì¸í”„ë¼ì§€ìˆ˜"] = merged_df[[f"{col}_ì •ê·œí™”" for col in infra_cols]].mean(axis=1)


# í´ëŸ¬ìŠ¤í„°ë§ - êµí†µ ì¸í”„ë¼ ìˆ˜ì¤€ì´ ë¹„ìŠ·í•œ ì§€ì—­ë¼ë¦¬ ìë™ìœ¼ë¡œ ë¬¶ì–´ì¤Œ
kmeans = KMeans(n_clusters=3, random_state=42)
merged_df["í´ëŸ¬ìŠ¤í„°"] = kmeans.fit_predict(merged_df[["êµí†µì¸í”„ë¼ì§€ìˆ˜"]])

# ìƒê´€ê´€ê³„ ë¶„ì„
corr = merged_df[["ì „ê¸°ì°¨ìˆ˜", "ì¶©ì „ì†Œìˆ˜", "ìì „ê±°ë³´ìœ ìˆ˜", "êµí†µì¸í”„ë¼ì§€ìˆ˜", "ì´ì‚°í™”ì§ˆì†Œ_í‰ê· "]].corr()

# ì¶œë ¥ ê²°ê³¼
print("\n[ì‹œë„ë³„ êµí†µ ì¸í”„ë¼ ìš”ì•½]")
print(merged_df[["ì‹œë„", "êµí†µì¸í”„ë¼ì§€ìˆ˜", "í´ëŸ¬ìŠ¤í„°", "ì´ì‚°í™”ì§ˆì†Œ_í‰ê· "]])

print("\n[ì „ê¸°ì°¨ ë° ëŒ€ê¸°ì˜¤ì—¼ ìƒê´€ê´€ê³„]")
print(corr[["ì´ì‚°í™”ì§ˆì†Œ_í‰ê· "]].sort_values(by="ì´ì‚°í™”ì§ˆì†Œ_í‰ê· "))

# ì €ì¥
merged_df.to_excel("êµí†µì¸í”„ë¼_ë¶„ì„ê²°ê³¼.xlsx", index=False)

